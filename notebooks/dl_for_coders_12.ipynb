{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12: A Language model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the gzipped text file\n",
    "url = \"https://github.com/lsb/human-numbers/blob/trunk/one-hundred-thousand-numbers.txt.gz?raw=true\"\n",
    "\n",
    "# Downloading the file using requests\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # This will raise an error if the download failed\n",
    "\n",
    "# Unzipping the content\n",
    "content = gzip.decompress(response.content).decode('utf-8')\n",
    "\n",
    "# Since the file contains numbers, each number on a new line, we can split the content into a list\n",
    "numbers = content.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(x for x in numbers)\n",
    "tokens = text.split(' ')\n",
    "\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(list(set(tokens)))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29, 14, 28, 25, 8, 6, 18, 15, 0, 11]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token to numbers\n",
    "word2idx = {w:i for i, w in enumerate(vocab)}\n",
    "idx2word = {i:w for i, w in enumerate(vocab)}\n",
    "nums = [word2idx[i] for i in tokens]\n",
    "nums[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 zero\n",
      "14 one\n",
      "28 two\n",
      "25 three\n",
      "8 four\n",
      "6 five\n",
      "18 six\n",
      "15 seven\n",
      "0 eight\n",
      "11 nine\n",
      "21 ten\n",
      "3 eleven\n",
      "26 twelve\n",
      "22 thirteen\n",
      "9 fourteen\n",
      "4 fifteen\n",
      "19 sixteen\n",
      "16 seventeen\n",
      "1 eighteen\n",
      "12 nineteen\n",
      "27 twenty\n",
      "27 twenty\n",
      "14 one\n",
      "27 twenty\n",
      "28 two\n"
     ]
    }
   ],
   "source": [
    "for idx in nums[:25]:\n",
    "    print(idx, vocab[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three tokens: ['a', 'b', 'c'], Next token: d, Step: 0\n",
      "Three tokens: ['b', 'c', 'd'], Next token: e, Step: 1\n",
      "Three tokens: ['c', 'd', 'e'], Next token: f, Step: 2\n",
      "Three tokens: ['d', 'e', 'f'], Next token: g, Step: 3\n",
      "Three tokens: ['e', 'f', 'g'], Next token: h, Step: 4\n",
      "Three tokens: ['f', 'g', 'h'], Next token: i, Step: 5\n",
      "Three tokens: ['g', 'h', 'i'], Next token: j, Step: 6\n",
      "Three tokens: ['h', 'i', 'j'], Next token: k, Step: 7\n"
     ]
    }
   ],
   "source": [
    "dummy_tokens = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']  # Example list\n",
    "\n",
    "for i in range(0, len(dummy_tokens) - 3, 1):\n",
    "    three_tokens = dummy_tokens[i:i+3]  # Get a slice of three tokens\n",
    "    next_token = dummy_tokens[i+3]      # Get the token immediately following the slice\n",
    "    print(f\"Three tokens: {three_tokens}, Next token: {next_token}, Step: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['hundred', 'ninety', 'three'], 'five'),\n",
       " (['ninety', 'three', 'five'], 'hundred'),\n",
       " (['three', 'five', 'hundred'], 'ninety'),\n",
       " (['five', 'hundred', 'ninety'], 'four'),\n",
       " (['hundred', 'ninety', 'four'], 'five'),\n",
       " (['ninety', 'four', 'five'], 'hundred'),\n",
       " (['four', 'five', 'hundred'], 'ninety'),\n",
       " (['five', 'hundred', 'ninety'], 'five'),\n",
       " (['hundred', 'ninety', 'five'], 'five'),\n",
       " (['ninety', 'five', 'five'], 'hundred'),\n",
       " (['five', 'five', 'hundred'], 'ninety'),\n",
       " (['five', 'hundred', 'ninety'], 'six'),\n",
       " (['hundred', 'ninety', 'six'], 'five'),\n",
       " (['ninety', 'six', 'five'], 'hundred'),\n",
       " (['six', 'five', 'hundred'], 'ninety'),\n",
       " (['five', 'hundred', 'ninety'], 'seven'),\n",
       " (['hundred', 'ninety', 'seven'], 'five'),\n",
       " (['ninety', 'seven', 'five'], 'hundred'),\n",
       " (['seven', 'five', 'hundred'], 'ninety'),\n",
       " (['five', 'hundred', 'ninety'], 'eight')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### predict next token based on three previous tokens; book uses step size of 3 which has no overlap, i prefer 1\n",
    "[(tokens[i:i+3], tokens[i+3]) for i in range(0, len(tokens)-3, 1)][2000:2020] # change from 4-2 to 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming 'mps_device' is defined as your MPS device\n",
    "mps_device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset karpathy style\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(0, len(tokens) - 3, 1):\n",
    "    three_tokens = torch.tensor(nums[i:i+3])  # Get a slice of three tokens\n",
    "    next_token = torch.tensor(nums[i+3])      # Get the token immediately following the slice\n",
    "    xs.append(three_tokens)\n",
    "    ys.append(next_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_most_common_scalar(data):\n",
    "    \"\"\"given list of scalars, find the most comon scalar value\"\"\"\n",
    "    counter = Counter(data)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return idx2word[most_common.item()]\n",
    "\n",
    "get_most_common_scalar(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class LLMModel1(nn.Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        super(LLMModel1, self).__init__()  # Initialize the superclass\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden) #vocab to hidden\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden) # hidden to hidden\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size) # hidden to vocab (logits)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"hidden states are accumulated. subsequent hidden state is added to embedding of next token before being passed through next linear layer and ReLU\"\"\"\n",
    "        # create first hidden state from first word\n",
    "        # embed --> linear --> relu\n",
    "        h = F.relu(self.h_h(self.i_h(x[:, 0])))\n",
    "\n",
    "        # second hidden state from second word\n",
    "        h = h + self.i_h(x[:, 1])\n",
    "        h = F.relu(self.h_h(h))\n",
    "\n",
    "        # hidden state from third word\n",
    "        h = h + self.i_h(x[:, 2])\n",
    "        h = F.relu(self.h_h(h))\n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming X and Y are your data tensors\n",
    "X = torch.stack(xs)\n",
    "Y = torch.stack(ys)\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "# Calculate the sizes of splits\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset (this method shuffles the data)\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset without shuffling\n",
    "train_dataset = TensorDataset(X[:train_size], Y[:train_size])\n",
    "val_dataset = TensorDataset(X[train_size:], Y[train_size:])\n",
    "\n",
    "# Create data loaders with drop_last=True to ensure all batches have the same size\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for batch in progress_bar:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            avg_loss = total_loss / total\n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix(loss=avg_loss, accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        train_accuracies.append(100 * correct / total)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Validation]')\n",
    "        with torch.no_grad():\n",
    "            for batch in progress_bar:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                # Update progress bar\n",
    "                avg_loss = total_loss / total\n",
    "                accuracy = 100 * correct / total\n",
    "                progress_bar.set_postfix(loss=avg_loss, accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "        val_losses.append(total_loss / len(val_loader))\n",
    "        val_accuracies.append(100 * correct / total)\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [Train]: 100%|██████████| 7762/7762 [00:44<00:00, 173.98it/s, accuracy=54.25%, loss=0.022] \n",
      "Epoch 1/2 [Validation]: 100%|██████████| 1940/1940 [00:05<00:00, 331.82it/s, accuracy=39.38%, loss=0.0358]\n",
      "Epoch 2/2 [Train]: 100%|██████████| 7762/7762 [00:42<00:00, 184.61it/s, accuracy=53.56%, loss=0.022] \n",
      "Epoch 2/2 [Validation]: 100%|██████████| 1940/1940 [00:05<00:00, 365.05it/s, accuracy=40.01%, loss=0.0386]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "n_hidden = 64\n",
    "model = LLMModel1(vocab_size, n_hidden)\n",
    "model.to(mps_device)  # Move model to MPS device\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "num_epochs = 2\n",
    "device = mps_device\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies, model = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 8030\n",
      "input sequence: ['one', 'two', 'three'].\n",
      "prediction: eighty\n",
      "input sequence: ['twenty', 'one', 'twenty'].\n",
      "prediction: nine\n",
      "input sequence: ['zero', 'one', 'two'].\n",
      "prediction: thousand\n",
      "input sequence: ['one', 'hundred', 'one'].\n",
      "prediction: eighty\n"
     ]
    }
   ],
   "source": [
    "# print number of params in model\n",
    "def print_params(model):\n",
    "    num_params = 0\n",
    "    for param in model.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(f\"#Params: {num_params}\")\n",
    "    return num_params\n",
    "\n",
    "def predict_next_word(model, input_sequence, word2idx, idx2word):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert the input sequence to a tensor of word indices\n",
    "    input_indices = [word2idx[word] for word in input_sequence]\n",
    "    input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0)  # Add a batch dimension\n",
    "    input_tensor = input_tensor.to(device)  # Move the tensor to the appropriate device\n",
    "    \n",
    "    # Get the prediction\n",
    "    with torch.no_grad():  # No need to track gradients for prediction\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # Get the predicted word index\n",
    "    _, predicted_index = torch.max(output, 1) # output is of shape (1, vocab_size)\n",
    "    predicted_index = predicted_index.item()  # Convert to a Python integer\n",
    "    \n",
    "    # Convert the predicted index to the corresponding word\n",
    "    predicted_word = idx2word[predicted_index]\n",
    "    print(f'input sequence: {input_sequence}.\\nprediction: {predicted_word}')\n",
    "    model.reset()\n",
    "\n",
    "\n",
    "print_params(model)\n",
    "\n",
    "# Example usage\n",
    "input_sequence = ['one', 'two', 'three']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['twenty', 'one', 'twenty']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['zero', 'one', 'two']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['one', 'hundred', 'one']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thousand'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence = ['twenty', 'one', 'twenty']\n",
    "\n",
    "model.eval()\n",
    "    \n",
    "# Convert the input sequence to a tensor of word indices\n",
    "input_indices = [word2idx[word] for word in input_sequence]\n",
    "input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0)  # Add a batch dimension\n",
    "input_tensor = input_tensor.to(device)  # Move the tensor to the appropriate device\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients for prediction\n",
    "    output = model(input_tensor)\n",
    "\n",
    "_, predicted_index = torch.max(output, 1) # output is of shape (1, vocab_size)\n",
    "predicted_index = predicted_index.item()  # Convert to a Python integer\n",
    "    \n",
    "# Convert the predicted index to the corresponding word\n",
    "predicted_word = idx2word[predicted_index]\n",
    "\n",
    "predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accuracies=None, val_accuracies=None):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Training loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy if provided\n",
    "    if train_accuracies and val_accuracies:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, train_accuracies, 'bo-', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracies, 'ro-', label='Validation accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refactor to RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class LLMModel2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        super(LLMModel2, self).__init__()  # Initialize the superclass\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden) #vocab to hidden\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden) # hidden to hidden\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size) # hidden to vocab (logits)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"hidden states are accumulated. subsequent hidden state is added to embedding of next token before being passed through next linear layer and ReLU\"\"\"\n",
    "        h = 0\n",
    "        for i in range(3):\n",
    "            h = h + self.i_h(x[:, i])\n",
    "            h = F.relu(self.h_h(h))\n",
    "        return self.h_o(h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [Train]: 100%|██████████| 7762/7762 [00:42<00:00, 182.56it/s, accuracy=54.77%, loss=0.0219]\n",
      "Epoch 1/2 [Validation]: 100%|██████████| 1940/1940 [00:05<00:00, 340.73it/s, accuracy=40.17%, loss=0.035] \n",
      "Epoch 2/2 [Train]: 100%|██████████| 7762/7762 [00:42<00:00, 181.92it/s, accuracy=54.16%, loss=0.022] \n",
      "Epoch 2/2 [Validation]: 100%|██████████| 1940/1940 [00:05<00:00, 357.87it/s, accuracy=40.08%, loss=0.0376]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "n_hidden = 64\n",
    "model = LLMModel2(vocab_size, n_hidden)\n",
    "model.to(mps_device)  # Move model to MPS device\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies, model = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: ['one', 'two', 'three'].\n",
      "prediction: thousand\n",
      "input sequence: ['twenty', 'one', 'twenty'].\n",
      "prediction: five\n",
      "input sequence: ['zero', 'one', 'two'].\n",
      "prediction: thousand\n",
      "input sequence: ['one', 'hundred', 'one'].\n",
      "prediction: eighty\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sequence = ['one', 'two', 'three']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['twenty', 'one', 'twenty']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['zero', 'one', 'two']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['one', 'hundred', 'one']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maintaining hidden state\n",
    "\n",
    "- instead of resetting to 0 for each forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class LLMModel3(nn.Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        super(LLMModel3, self).__init__()  # Initialize the superclass\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden) #vocab to hidden\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden) # hidden to hidden\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size) # hidden to vocab (logits)\n",
    "        self.h = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"hidden states are accumulated. subsequent hidden state is added to embedding of next token before being passed through next linear layer and ReLU\"\"\"\n",
    "        for i in range(3):\n",
    "            self.h = self.h + self.i_h(x[:, i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "        out = self.h_o(self.h)\n",
    "        self.h = self.h.detach() # stop tracking previous gradients\n",
    "        return out\n",
    "\n",
    "    def reset(self):\n",
    "        # Resets or reinitializes the hidden state to zero\n",
    "        self.h = 0\n",
    "\n",
    "\n",
    "# detach means we only calculate gradients of previous 3 steps (for loop) aka the steps used to calculate this self.h; this is used to avoid vanishing/exploding graidnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [Train]: 100%|██████████| 7762/7762 [00:41<00:00, 188.43it/s, accuracy=57.40%, loss=0.0198]\n",
      "Epoch 1/2 [Validation]: 100%|██████████| 1940/1940 [00:05<00:00, 352.54it/s, accuracy=41.06%, loss=0.039] \n",
      "Epoch 2/2 [Train]: 100%|██████████| 7762/7762 [00:41<00:00, 188.28it/s, accuracy=57.70%, loss=0.0194]\n",
      "Epoch 2/2 [Validation]: 100%|██████████| 1940/1940 [00:05<00:00, 353.96it/s, accuracy=38.95%, loss=0.0394]\n"
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "model = LLMModel3(vocab_size, n_hidden)\n",
    "model.to(mps_device)  # Move model to MPS device\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies, model = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 8030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8030"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMModel3(\n",
       "  (i_h): Embedding(30, 64)\n",
       "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (h_o): Linear(in_features=64, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sequence: ['one', 'two', 'three'].\n",
      "prediction: thousand\n",
      "input sequence: ['twenty', 'one', 'twenty'].\n",
      "prediction: nine\n",
      "input sequence: ['zero', 'one', 'two'].\n",
      "prediction: thousand\n",
      "input sequence: ['one', 'hundred', 'one'].\n",
      "prediction: eighty\n"
     ]
    }
   ],
   "source": [
    "model.reset()\n",
    "\n",
    "# Example usage\n",
    "input_sequence = ['one', 'two', 'three']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['twenty', 'one', 'twenty']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['zero', 'one', 'two']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n",
    "input_sequence = ['one', 'hundred', 'one']\n",
    "predict_next_word(model, input_sequence, word2idx, idx2word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slight boost in performance..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now instead of outputting one word per three input words, output after each step...\n",
    "\n",
    "this gives it more signal for back prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([11, 10, 13, 11], [10, 13, 11])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl = 16\n",
    "nums[i:i+sl], nums[i+1:i+sl+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset karpathy style\n",
    "sl = 16\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(0, len(nums) - sl-1, 1):\n",
    "    sixteen_tokens = torch.tensor(nums[i:i+16])  # Get a slice of three tokens\n",
    "    next_sixteen_tokens = torch.tensor(nums[i+1: i+sl+1])      # Get the token immediately following the slice\n",
    "    xs.append(sixteen_tokens)\n",
    "    ys.append(next_sixteen_tokens)\n",
    "\n",
    "# Assuming X and Y are your data tensors\n",
    "X = torch.stack(xs)\n",
    "Y = torch.stack(ys)\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "# Calculate the sizes of splits\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset (this method shuffles the data)\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset without shuffling\n",
    "train_dataset = TensorDataset(X[:train_size], Y[:train_size])\n",
    "val_dataset = TensorDataset(X[train_size:], Y[train_size:])\n",
    "\n",
    "# Create data loaders with drop_last=True to ensure all batches have the same size\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "five\n",
      "six\n",
      "seven\n",
      "eight\n",
      "nine\n",
      "ten\n",
      "eleven\n",
      "twelve\n",
      "thirteen\n",
      "fourteen\n",
      "fifteen\n",
      "sixteen\n",
      "\n",
      "\n",
      "two\n",
      "three\n",
      "four\n",
      "five\n",
      "six\n",
      "seven\n",
      "eight\n",
      "nine\n",
      "ten\n",
      "eleven\n",
      "twelve\n",
      "thirteen\n",
      "fourteen\n",
      "fifteen\n",
      "sixteen\n",
      "seventeen\n"
     ]
    }
   ],
   "source": [
    "i_ = 1\n",
    "xs[i_], ys[i_]\n",
    "\n",
    "for num in xs[i_]:\n",
    "    print(vocab[num])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for num in ys[i_]:\n",
    "    print(vocab[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class LLMModel4(nn.Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        super(LLMModel4, self).__init__()  # Initialize the superclass\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden) #vocab to hidden\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden) # hidden to hidden\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size) # hidden to vocab (logits)\n",
    "        self.h = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"output a prediction after each word\n",
    "\n",
    "        will return outs as shape batch_size x seq_len x vocab_sz\n",
    "        \"\"\"\n",
    "        outs = [] # (batch_size x vocab_sz)\n",
    "        for i in range(sl): # CHANGED TO SL\n",
    "            self.h = self.h + self.i_h(x[:, i])\n",
    "            self.h = F.relu(self.h_h(self.h))\n",
    "            outs.append(self.h_o(self.h))\n",
    "        self.h = self.h.detach() # stop tracking previous gradients\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "    def reset(self):\n",
    "        # Resets or reinitializes the hidden state to zero\n",
    "        self.h = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumb but we'll update the function for outputs.shape\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for batch in progress_bar:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # FLATTTEN AND RESHAPE\n",
    "            outputs = outputs.view(-1, vocab_size)\n",
    "            labels = labels.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            avg_loss = total_loss / total\n",
    "            accuracy = 100 * correct / total\n",
    "            progress_bar.set_postfix(loss=avg_loss, accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "        train_losses.append(total_loss / len(train_loader))\n",
    "        train_accuracies.append(100 * correct / total)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Validation]')\n",
    "        with torch.no_grad():\n",
    "            for batch in progress_bar:\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                outputs = outputs.view(-1, vocab_size)\n",
    "                labels = labels.view(-1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                # Update progress bar\n",
    "                avg_loss = total_loss / total\n",
    "                accuracy = 100 * correct / total\n",
    "                progress_bar.set_postfix(loss=avg_loss, accuracy=f'{accuracy:.2f}%')\n",
    "\n",
    "        val_losses.append(total_loss / len(val_loader))\n",
    "        val_accuracies.append(100 * correct / total)\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|██████████| 7762/7762 [01:57<00:00, 66.31it/s, accuracy=55.41%, loss=0.00131]\n",
      "Epoch 1/5 [Validation]: 100%|██████████| 1940/1940 [00:11<00:00, 163.80it/s, accuracy=25.69%, loss=0.00279]\n",
      "Epoch 2/5 [Train]: 100%|██████████| 7762/7762 [01:57<00:00, 66.33it/s, accuracy=57.04%, loss=0.00126]\n",
      "Epoch 2/5 [Validation]: 100%|██████████| 1940/1940 [00:11<00:00, 171.43it/s, accuracy=28.11%, loss=0.00273]\n",
      "Epoch 3/5 [Train]: 100%|██████████| 7762/7762 [01:57<00:00, 66.34it/s, accuracy=51.70%, loss=0.00147]\n",
      "Epoch 3/5 [Validation]: 100%|██████████| 1940/1940 [00:11<00:00, 170.65it/s, accuracy=27.86%, loss=0.00262]\n",
      "Epoch 4/5 [Train]: 100%|██████████| 7762/7762 [01:56<00:00, 66.42it/s, accuracy=51.60%, loss=0.00145]\n",
      "Epoch 4/5 [Validation]: 100%|██████████| 1940/1940 [00:11<00:00, 162.80it/s, accuracy=27.38%, loss=0.0025] \n",
      "Epoch 5/5 [Train]: 100%|██████████| 7762/7762 [01:59<00:00, 64.82it/s, accuracy=51.88%, loss=0.00146]\n",
      "Epoch 5/5 [Validation]: 100%|██████████| 1940/1940 [00:11<00:00, 163.96it/s, accuracy=28.78%, loss=0.00253]\n"
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "\n",
    "\n",
    "model = LLMModel4(vocab_size, n_hidden)\n",
    "model.to(mps_device)  # Move model to MPS device\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accuracies, val_accuracies = train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thousand',\n",
       " 'eighty',\n",
       " 'eighty',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'seventy',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'seventy',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'seventy',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'seventy',\n",
       " 'seventy']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your sequence length\n",
    "sl = 16\n",
    "\n",
    "model.reset()\n",
    "\n",
    "# Make sure to have your word2idx dictionary ready to convert words to indices\n",
    "input_sequence = ['one', 'hundred', 'one', \n",
    "                  'one', 'hundred', 'two',\n",
    "                  'one', 'hundred', 'three', \n",
    "                  'one', 'hundred', 'four',\n",
    "                  'one', 'hundred', 'five',\n",
    "                  'one']  # sequence of length sl\n",
    "\n",
    "# Convert input sequence to tensor of word indices\n",
    "input_indices = [word2idx[word] for word in input_sequence]\n",
    "input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "input_tensor = input_tensor.to(device)  # Move to the appropriate device\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    logits = model(input_tensor)  # Logits will have shape [1, sl, vocab_size] since we did unsqueeze\n",
    "\n",
    "# If you want to get the most likely word predictions for each position in the sequence:\n",
    "predictions = torch.argmax(logits, dim=2)  # This will give you [1, sl] tensor of word indices\n",
    "\n",
    "# Convert predicted indices to words\n",
    "predicted_words = [idx2word[idx.item()] for idx in predictions[0]]\n",
    "predicted_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-layer RNNs \n",
    "\n",
    "will suffer from exploding...vanishing gradients..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.forget_gate = nn.Linear(ni + nh, nh) # since we stack ni + nh into one tensor\n",
    "        self.input_gate = nn.Linear(ni + nh, nh)\n",
    "        self.cell_gate = nn.Linear(ni + nh, nh)\n",
    "        self.output_gate = nn.Linear(ni + nh, nh)\n",
    "    \n",
    "    def forward(self, input, state):\n",
    "        h, c = state # hidden state and cell state \n",
    "        h = torch.stack([h, input], dim=1) # stack h and input together\n",
    "\n",
    "        # forget cell state\n",
    "        forget = torch.sigmoid(self.forget_gate(h)) # linear then sigmoid will squash values between 0 and 1\n",
    "        c = c * forget # multiply by forget gate; aka what should we forget or remember\n",
    "\n",
    "        # update cell state\n",
    "        inp = torch.sigmoid(self.input_gate(h)) # what should we update; will be between 0 and 1\n",
    "        cell = torch.tanh(self.cell_gate(h)) # what should the updated values be; will be between -1 and 1\n",
    "        c = c + (inp * cell)\n",
    "\n",
    "        # generate new hidden state, using h and c\n",
    "        out = torch.sigmoid(self.output_gate(h)) # between 0 and 1\n",
    "        h = out * torch.tanh(c) # multipled by tanh which is between -1 and 1\n",
    "        return h, (h, c)\n",
    "    \n",
    "### Refactor for speed into one giant matrix multiplication\n",
    "    \n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, ni, nh):\n",
    "        self.ih = nn.Linear(ni, 4 * nh)\n",
    "        self.hh = nn.Linear(nh, 4 * nh)\n",
    "    \n",
    "    def forward(self, input, state):\n",
    "        h, c = state # hidden state and cell state \n",
    "        # One big matmul for all gates\n",
    "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
    "        ingate, forgetgate, outgate = map(torch.sigmoid, gates[:3]) \n",
    "        cellgate = gates[3].tanh()\n",
    "\n",
    "        c = (forgetgate * c) + (ingate * cellgate)\n",
    "        h = outgate * c.tanh()\n",
    "        return h, (h, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4]), tensor([5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(0, 10); t\n",
    "\n",
    "t.chunk(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "x * ih -> [batch_size, ni] * [ni, 4*nh] = [batch_size, 4*nh]\n",
    "h * hh -> [batch_size, nh] * [nh, 4*nh] = [batch_size, 4*nh]\n",
    "gates = (x * ih) + (h * hh) -> [batch_size, 4*nh]\n",
    "\n",
    "ingate, forgetgate, outgate, cellgate = gates.chunk(4, 1)\n",
    "\n",
    "\n",
    "ingate = sigmoid([batch_size, nh])\n",
    "forgetgate = sigmoid([batch_size, nh])\n",
    "outgate = sigmoid([batch_size, nh])\n",
    "cellgate = tanh([batch_size, nh])\n",
    "\n",
    "c = (forgetgate * c) + (ingate * tanh(cellgate))\n",
    "h = outgate * tanh(c)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detour of detach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a simple computation graph\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "# Without detach\n",
    "z = y * y  # z = (x * 2) * (x * 2) = 4x^2\n",
    "z.backward()  # Computes gradients for the whole graph\n",
    "gradients_without_detach = x.grad.item()  # Should be dz/dx = 8x, which is 16 when x = 2\n",
    "\n",
    "# Resetting gradients\n",
    "x.grad.data.zero_()\n",
    "\n",
    "# With detach\n",
    "y_detached = y.detach()  # y_detached is a new tensor with the same value as y but no history of operations\n",
    "# No need to call z.backward() because y_detached has no grad_fn\n",
    "# and thus won't contribute to gradients in x\n",
    "\n",
    "# The gradient of x should still be zero since the detached part does not contribute to the computation\n",
    "gradients_with_detach = x.grad.item()\n",
    "\n",
    "gradients_without_detach, gradients_with_detach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## torch.stack()\n",
    "lst = [torch.rand(2, 3) for i in range(3)]\n",
    "print([x.shape for x in lst])\n",
    "\n",
    "# stacking on dimension 1 maintains batch dimension, second dimension (1) becomes the timesteps\n",
    "torch.stack(lst, dim=1).shape, torch.stack(lst, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(lst, dim=0).shape, torch.stack(lst, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
